基于信息增益的方法
	划分出来的子树分类清晰
    熵：越大不确定越高，否则越小
从空树开始
过拟合：
	降低模型的复杂度：降低节点的数量
    控制深度到多少层
决策树对回归问题：
	回归问题的输出是一个实数
	对叶节点做平均，或者在叶节点上做线性拟合，
总结：
	最好拟合


神经网络：
	激活函数：
		数学上可以构造不同的
		线性函数，可以为零也可以为正
	神经网络的架构：
		全链接层数
		非全链接层（类似于穷举的方式）
		选择可优化

k-近邻方法：
	最有用的数据是当前数据邻居的信息
	分类问题：
		找k的邻居：
			分类问题：看邻居什么类别最多，那k就是这种分类
			回归问题：对k的邻居做平均，或者线性回归
		如何定义k的邻居：
			距离k最近的点
		优点：
			训练没有太多的开销

支持向量机：
	两纬样本线性糙平面，可选的线性糙平面
	对于线性可分的：直线到点的距离平方最短
	对于线性不可分的：升纬，二维线性升到三纬就是线性可分的学习器

######################
集成学习：
	（线性模型不够复杂）比赛常用
	简介：
		多个学习模型组合在一起


	